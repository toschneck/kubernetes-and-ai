
#
persistence:
  models:
    enabled: true
    annotations: {}
    storageClass: ""
    accessModes:
      - ReadWriteOnce
      #- ReadWriteMany
    size: 100Gi
    globalMount: /models
  output:
    enabled: true
    annotations: {}
    storageClass: ""
    accessModes:
      - ReadWriteOnce
      #- ReadWriteMany
    size: 5Gi
    globalMount: /tmp/generated

deployment:
  image:
    repository: quay.io/go-skynet/local-ai  # Example: "docker.io/myapp"
    # https://localai.io/basics/container/
    #Images containing the aio tag are all-in-one images with all the features enabled, and come with an opinionated set of configuration.
    #tag: latest-aio-gpu-nvidia-cuda-12
    tag: v2.18.1-aio-gpu-nvidia-cuda-12
    #tag: v2.23.0-aio-gpu-nvidia-cuda-12


#service:
  # type: LoadBalancer
  # If deferring to an internal only load balancer
  # externalTrafficPolicy: Local
#  port: 80
  #annotations:
  #  "external-dns.alpha.kubernetes.io/hostname": "localai-kcd.demo.kubermatic.io."
  # If using an AWS load balancer, you'll need to override the default 60s load balancer idle timeout
  # service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "1200"

ingress:
  enabled: true
  className: "nginx"
  annotations:
    #kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    #cert-manager.io/cluster-issuer: "letsencrypt-staging-nginx"
    #external-dns.alpha.kubernetes.io/hostname: localai-cl.demo.kubermatic.io
  hosts:
    - host: localai.tobi-ai.lab.kubermatic.io
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: local-ai-tls
      hosts:
      - localai.tobi-ai.lab.kubermatic.io

# schedule only on GPU nodes
#nodeSelector:
#  type: gpu
tolerations:
  - key: workload
    operator: "Equal"
    value: "gpu"
    effect: "NoSchedule"

# Ensures that the nvidia driver is ready
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
     nodeSelectorTerms:
     - matchExpressions:
       - key: "nvidia.com/gpu.product"
         operator: Exists